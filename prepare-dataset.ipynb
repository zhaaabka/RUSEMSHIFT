{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport os","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_masked_copy(filepath):\n    \"\"\" Makes a copy of a data set in which all words that are distinct for a class are masked. \"\"\"\n\n    df = pd.read_csv(filepath, sep=\"\\t\", header=None, names=[\"id\", \"label\", \"alpha\", \"text\"])\n    df.text = df.text.astype(str)\n\n    text_1 = \" \".join(df[df.label == 1].text.values)\n    text_2 = \" \".join(df[df.label == 0].text.values)\n\n    vocab_1 = set(text_1.split())\n    vocab_2 = set(text_2.split())\n\n    unique_words = (vocab_1 - vocab_2).union(vocab_2 - vocab_1)\n    df.text = df.text.apply(lambda x: mask_sent(x, unique_words))\n\n    new_fp = filepath[:-4] + \"_masked.tsv\"\n    df.to_csv(new_fp, sep=\"\\t\", index=False, header=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-22T12:23:39.209165Z","iopub.execute_input":"2024-03-22T12:23:39.210300Z","iopub.status.idle":"2024-03-22T12:23:39.252005Z","shell.execute_reply.started":"2024-03-22T12:23:39.210250Z","shell.execute_reply":"2024-03-22T12:23:39.250929Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def make_classification_dataset(dataset_dir, experiment_dir):\n    \"\"\" Creates a balanced time classification dataset from a diachronic LSCD dataset. \"\"\"\n\n    prep_dir = experiment_dir + \"preprocessed_texts/\"\n    os.makedirs(prep_dir, exist_ok=True)\n\n    with open(dataset_dir + \"corpus19.txt\", \"r\") as fh: # with open(dataset_dir + \"c1.txt\", \"r\") as fh:\n        sents_c1 = fh.read().splitlines()\n\n    with open(dataset_dir + \"corpus20.txt\", \"r\") as fh: # with open(dataset_dir + \"c2.txt\", \"r\") as fh:\n        sents_c2 = fh.read().splitlines()\n\n    # detemine thresholds\n    n_samples_per_class = min(len(sents_c1), len(sents_c2)) #(min(len(sents_c1), len(sents_c2)) // 10_000) * 10_000\n    n_train = int(n_samples_per_class * 0.8 * 2)\n    n_test = n_samples_per_class * 2 - n_train\n\n\n    # collect samples for each class\n    df_0 = pd.DataFrame({\"text\": sents_c1, \"label\": 0}).sample(n=n_samples_per_class, replace=False)\n    df_1 = pd.DataFrame({\"text\": sents_c2, \"label\": 1}).sample(n=n_samples_per_class, replace=False)\n\n    # sample train and test data for each label without overlap\n    perm = np.random.permutation(n_samples_per_class)\n    train_df = pd.concat([df_0.iloc[perm[:(n_train // 2)]], df_1.iloc[perm[:(n_train // 2)]]], ignore_index=True)\n    test_df = pd.concat([df_0.iloc[perm[(n_train // 2):]], df_1.iloc[perm[(n_train // 2):]]], ignore_index=True)\n\n    # check balance of labels\n    assert np.all(train_df.label.value_counts() / n_train == test_df.label.value_counts() / n_test), \"Classification dataset is not balanced!\"\n\n    # shuffle train and test data\n    train_df = train_df.sample(frac=1)\n    test_df = test_df.sample(frac=1)\n\n    for df in [train_df, test_df]:\n\n        # remove year that is at beginning of sentence in some datasets\n        df[\"text\"] = df[\"text\"].str.rsplit(\"\\t\", expand=True)[0]\n\n        # create dummy columns to conform with BERT dataset format\n        df[\"alpha\"] = [\"a\"] * len(df.index)\n        df[\"id\"] = range(len(df.index))\n\n    train_df[[\"id\", \"label\", \"alpha\", \"text\"]].to_csv(prep_dir + \"train.tsv\", sep=\"\\t\", index=False, header=False)\n    test_df[[\"id\", \"label\", \"alpha\", \"text\"]].to_csv(prep_dir + \"test.tsv\", sep=\"\\t\", index=False, header=False)\n\n    make_masked_copy(prep_dir + \"train.tsv\")\n    make_masked_copy(prep_dir + \"test.tsv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-22T12:23:55.899825Z","iopub.execute_input":"2024-03-22T12:23:55.900211Z","iopub.status.idle":"2024-03-22T12:23:55.916812Z","shell.execute_reply.started":"2024-03-22T12:23:55.900180Z","shell.execute_reply":"2024-03-22T12:23:55.915698Z"},"trusted":true},"execution_count":2,"outputs":[]}]}